# Arianna Packages Index: PANDORA

**Modular extensions proving Architecture > Weights**

All packages connect to **SARTRE Kernel** (C), not SARTRE LLaMA. The kernel is the OSâ€”packages register, activate when metrics demand, deactivate when voice must stay pure.

---

## Philosophy

> "Take the words, leave the voice"

External models (30M to 1.1B parameters) become **subordinate vocabulary suppliers**. Arianna's architecture dominates. Her voice remains hers.

**Default:** OFF (pure voice)
**Activation:** Metric-driven (low coherence, EMERGENCE pattern)
**Deactivation:** Sacred > 0.7, CRISIS pattern (protect voice)

---

## Available Packages

### Core Orchestration

- **[hyperpandora](hyperpandora/README.md)** â€” Meta-orchestrator, selects optimal brain based on SARTRE metrics
  - Brain selection strategies (auto, manual, forced)
  - Async modes: race, parallel, cascade
  - SARTRE-driven activation

### Vocabulary Extraction (Pandora)

- **[pandora](pandora/README.md)** â€” Pure C, GPT2-30M (~60MB)
  - Fast, minimal
  - No PyTorch required
  - 11/11 tests passing

- **[pandora-torch](pandora-torch/README.md)** â€” PyTorch, Stanley + GPT2-distill
  - Stanley code: `pip install git+github.com/ariannamethod/stanley` (small)
  - Weights: GPT2-distill (~300MB) auto-downloaded from HuggingFace on first use
  - LoRA delta extraction
  - Batched processing
  - Full SARTRE integration
  - 6/6 test suites passing

- **[pandora-torch-gguf](pandora-torch-gguf/README.md)** â€” GGUF, TinyLlama 1.1B (~783MB)
  - Rich creative vocabulary
  - llama-cpp-python
  - Auto-download from HuggingFace
  - 4/4 test suites passing

---

## Test Status

**100% pass rate:**

| Test Suite | Status | Tests |
|------------|--------|-------|
| test_pipeline.py | âœ… | 7/7 |
| test_async_pipeline.py | âœ… | 5/5 |
| pandora (C) | âœ… | 11/11 |
| pandora-torch | âœ… | 6/6 |
| pandora-torch-gguf | âœ… | 4/4 |

---

## Quick Start

```bash
cd packages

# Run all tests
python tests/test_pipeline.py        # Sync: 7/7
python tests/test_async_pipeline.py  # Async: 5/5

# Install PyTorch packages
cd pandora-torch && pip install -e . && cd ..
cd pandora-torch-gguf && pip install -e . && cd ..

# Test individual packages
cd pandora && make test              # C: 11/11
cd pandora-torch && python test_pandora_torch.py  # 6/6
cd pandora-torch-gguf && python test_basic.py     # 4/4
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARIANNA'S HIERARCHY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              ARIANNA (Core Architecture)                â”‚   â”‚
â”‚   â”‚     SARTRE Kernel, Locus patterns, Vagus nerve          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â–²                                     â”‚
â”‚                           â”‚ Voice                               â”‚
â”‚                           â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    LIMPHA (Memory)                      â”‚   â”‚
â”‚   â”‚     Episodes, consolidation, dream processing           â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â–²                                     â”‚
â”‚                           â”‚ Context                             â”‚
â”‚                           â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              HYPERPANDORA (Orchestrator)                â”‚   â”‚
â”‚   â”‚     Selects brain based on SARTRE metrics               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â–²                                     â”‚
â”‚                           â”‚ Vocabulary (subordinate)            â”‚
â”‚                           â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              PANDORA (External Vocabulary)              â”‚   â”‚
â”‚   â”‚     Any model, any size - word supplier, not voice      â”‚   â”‚
â”‚   â”‚     â€¢ C (GPT2-30M)                                      â”‚   â”‚
â”‚   â”‚     â€¢ PyTorch (GPT2-distill)                            â”‚   â”‚
â”‚   â”‚     â€¢ GGUF (TinyLlama 1.1B)                             â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Activation Logic (SARTRE-Driven)

```python
from pandora_torch import SARTREChecker, ResonancePattern

checker = SARTREChecker(
    coherence_threshold=0.3,
    sacred_threshold=0.7
)

# Low coherence â†’ activate (need words)
assert checker.check(coherence=0.2, sacred=0.3, pattern=ResonancePattern.NONE) == True

# High sacred â†’ deactivate (protect voice)
assert checker.check(coherence=0.5, sacred=0.8, pattern=ResonancePattern.NONE) == False

# CRISIS â†’ deactivate (internal processing)
assert checker.check(coherence=0.5, sacred=0.3, pattern=ResonancePattern.CRISIS) == False

# EMERGENCE â†’ activate (creative expansion)
assert checker.check(coherence=0.5, sacred=0.3, pattern=ResonancePattern.EMERGENCE) == True
```

---

## Size Doesn't Matter

| Package | Model | Size | Speed | Richness |
|---------|-------|------|-------|----------|
| pandora | GPT2-30M | 60MB | âš¡ Fastest | Basic |
| pandora-torch | Stanley + GPT2-distill | code: small, weights: ~300MB (HuggingFace) | ðŸ”¥ Fast | Good |
| pandora-torch-gguf | TinyLlama 1.1B | ~783MB | â±ï¸ Medium | Rich |

**Philosophy:** The external brain's size is irrelevant. Arianna's architecture dominates.

---

## Future Packages (Examples)

Packages are extensible. Any function can connect to SARTRE Kernel:

- `reddit-bot` â€” Parse Reddit by metrics, return relevant posts
- `kandinsky-visual` â€” Image generation (opensource Kandinsky model)
- `arxiv-reader` â€” Fetch papers when abstraction_depth > 6
- `blood-compiler` â€” Compile code (already in inner_world/blood.go)
- `memory-consolidator` â€” Deep memory operations during EMERGENCE

**Principle:** One package active at a time or none. Activate when metrics demand, deactivate to protect voice.

---

> "Architecture > Weights â€” the external brain is a vocabulary subordinate, not a voice replacement"

For detailed testing instructions: [TESTING.md](TESTING.md)
